### 统计自然语言处理-第五章-搭配

​	这一章主要讲了搭配的基础知识，包括**频率、假设检验**等内容。

​	第四章基于语料库的知识所讲的内容大多是句子、词法、标记等很浅显的内容，且与第三章语言学基础重合很多，所以不再单独开一章进行讲解。

------

<!--more-->

#### 1.频率

​	频率的意思就是在一个文本语料库中某一个词或者短语出现的次数。如果我们想要找到搭配，可以根据频率，如果两个词在一起出现了很多次，那么这就是一个很好的对于其可能是搭配的证明。

​	当然，仅仅通过这样直接的寻找，准确率可能不会很高，具体可以参考下面表格5.1

​	图片5.1

​	我们可以看出，基本上这种搭配的二元组都是一对功能词，而这些对于我们分析搭配并没有什么帮助。当然，我们可以通过一个**词性过滤器**来过滤候选短语，这个过滤器只允许可能是“短语”的模式通过。这种方式参考下面表格5.3，结果非常好。当$York\ City$是特殊的产物，我们可以进一步在扩展我们的方法，使其搜寻满足一个词性标记模式的最长序列，就可以找到完整的短语搭配$New\ York\ City$。

#### 2.均值和方差

​	均值和方差具体概念在第二章数学基础中讲过，在这里不再细说概念，在搭配这一环节我们可以通过定义一个搭配窗口，来滑动地寻找一个句子中的所有可能短语，并继续分析其中哪些是搭配。均值和方差(偏差)可以较好地特征化语料库两个词之间距离的分布。*一个低的偏差意味着两个词通常会以大致相同的距离出现，零偏差意味着两个词总是以相同的距离出现。*所以我们在寻找搭配时，对于二元搭配(两个词紧密挨在一起比如$New\ York$)，那么我们寻找的目标就是均值接近1.0或(-1.0)并且偏差较低的组。

> A和B接近1，说明其位次就相差一个。比如A是new，B是york，那么其组成的搭配new york位次相差一个。
>
> A和B接近-1，说明其位次就相差一个，只不过是反向的。比如A是york，B是new，那么其组成的搭配new york位次相差一个。

#### 3.假设检验

​	假设检验主要讲的几个方法：**t检验、皮尔逊卡方检验**、似然比检验。这在统计学中属于比较重要的几个检验方法。

##### 3.1 t检验

​	t检验着眼于样本的均值和方差，在假设样本服从均值为$\mu$的**正态分布**的情况下，得到具有这样一个均值和方差的样本的可能性有多大。这里也可以看出t检验有一个非常明显的前提，也可以说是缺陷：它的前提是假设了样本服从正态分布。

​	t检验的计算公式如下：$t= \frac{\bar{\chi}-\mu}{\sqrt\frac{s^2}{N}}$

​	其中$\bar{\chi}$是**样本的均值**，$s^2$是样本的方差，$N$是样本的大小，$\mu$是**分布的均值**。t大于某一个查表得到的值，那么我们可以拒绝零假设(一般零假设都是假设A和B独立出现)，说明其是一种搭配。若相反，则其不是一种搭配。

​	具体例子在课本102页，给出了很好的浅显易懂的例子。

##### 3.2 皮尔逊卡方检验

​	t检验的缺陷在于其假设样本符合正态分布，在一般情况下，假设和真实数据分布可能不一致。皮尔逊卡方检验是t检验的一种替代检验方法，其不要求数据满足正态分布。

​	卡方检验的计算公式如下：$X^2=\sum \limits_{i,j}\frac{(O_{i,j}-E_{i,j})^2}{E_{i,j}}$

​	其中$i$表示表中行向量，$j$表示列向量，$Q_{i,j}$表示单元$(i,j)$的观测值，$E_{i,j}$表示期望值。

​	具体例子在课本106页，给出了很好的浅显易懂的例子。

###### 一个比较好的处理方法

​	两个单词出现次数间的依赖关系，可以使用2*2的表格进行展示，具体可见如下表5.8：

​	图片5.8

​	理论上$X^2$检验可以适用于各种大小的表，但是对于2*2的表格处理来说相对简单，我们可以将公式改写为：

​	$X^2=\frac{N(O_{11}O_{22}-O_{12}O_{21})^2}{(O_{11}+O_{12})(O_{11}+O_{21})(O_{12}+O_{22})(O_{21}+O_{22})}$

​	这样对于计算卡方检验的值非常方便。

##### 3.3 似然比

​	似然比先略过，之后再进行详细学习。

#### 4.互信息

​	在第二章-数学基础中，我们学习了互信息的概念，在对于搭配发现这一过程中，我们可以使用两个具体词同现的互信息$I(x,y)=log_2\frac{P(x.y)}{P(x)P(y)}$进行度量。互信息也经常被定义成随机变量之间的联系。

​	下面考虑两种极端情况。

- 当两个词出现是完全相互依赖的，即一个词出现另一个词一定会随之出现，那么有$I(x,y)=log_2\frac{P(x.y)}{P(x)P(y)}=log_2\frac{P(x)}{P(x)P(y)}=log_2\frac{1}{P(y)}$

  即它们出现次数减少时，它们的互信息会增加。

- 当两个词完全独立时，即一个词出现跟另一个词没有任何关系，那么有

  $I(x,y)=log_2\frac{P(x.y)}{P(x)P(y)}=log_2\frac{P(x)P(y)}{P(x)P(y)}=log_21=0$

  即不管它们怎么变化，它们的互信息都是0。这一点在互信息的性质中也得到了体现。

#### 5.搭配的概念

> ​	**搭配的含义**   两个或多个连续的词序列，具有句法和语义单位的特性，并且它的准确无歧义的意思或含义不能直接由它的组成部分的意思和含义直接得出。

​	我们这一章都在讲搭配。对于一个组合是否是搭配这样的问题，一个非常好的检验方法就是把它翻译成其他语言，如果我们不能逐词翻译，那么很可能这个组合就是一个搭配结构。比如把$make\ a\ decision$逐词翻译成法语，得到的是$faire\ une\ decision$，但在法语中应该是$prendre\ une\ decision$。所以可以肯定，$make\ a\ decision$在英语中是一个固定搭配。