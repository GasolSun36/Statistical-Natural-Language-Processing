### 统计自然语言处理-第十四章-聚类

​	第十四章主要内容是聚类。聚类这个概念我在$Jiawei\ Han$老师的《$Data\ Mining:Concepts\ and\ techniques$》中有具体学过，当然在那本书中讲的比课本中要细很多，但是课本中的一些聚类方法是以文本作为基础的。具体可以看我的$github\ repo.$[https://github.com/MrSunCodes/Data-Mining-UIUC/tree/main/Cluster%20Analysis](https://github.com/MrSunCodes/Data-Mining-UIUC/tree/main/Cluster%20Analysis)

------

<!--more-->

#### 1.  基本概念

​	聚类的目标是将一组对象划分成若干组或类别，即相似的元素同组，不相似的元素不同组的划分过程。根据是否可划分到一个组可以分为**软聚类**和**硬聚类**。软聚类是数据可以划分到多个组，但是其属于各个类别的概率不同，而硬聚类是数据只能划分到一个组。又根据划分方法分成两种模式：**层级聚类**和**非层级聚类**。层级聚类之间的类别结构清晰，而非层级聚类的类别结构简单。

​	我们可以用树图形式来表示聚类情况，如下图所示。

​	图片1

​	各个词之间的相似度可以通过它们共同的祖先的高度来度量。共同祖先如果在根节点，则表明两个单词之间的相似度最低，反之最高。子类之间的相似度与它们所处的树节点的高度成反比，树节点和根节点距离越近，其子类之间的相似度越小。

> ​	这种树图形式不太常见，因为聚类的结果不太好这样可视化，只知道如何理解即可。

​	在语料库的大环境中，词的上下文可以提供很多信息，用来判断当前词的类别，即词的相邻上下文模式，来判断词之间的相似度，从而实现聚类操作。如果假设每个单词为一类，聚类过程就是不断地合并最近似模式类而形成新类的迭代过程。

​	聚类算法有两个用途，**试探性数据分析**和**概念的一般化**。试探性数据分析是指通过分析数据来理解现象的基本特性，从而使得后续工作更好的进展。概念的一般化是指在不确定某个数据点什么含义时，可以通过同类的其他元素进行代替(**即满足元素之间的可互换性**)从而更好的理解此数据。

#### 2. 层级聚类

​	层级聚类分为**自底向上**和**自顶向下**两种。两种算法非常简单，这里介绍一下它们的思想。

##### 	1. 自底向上

​		自底向上算法本质上是属于贪心算法，首先每个对象被初始化为一个类别集合，然后每次选取最相似的两个聚类合并为一个集合，不断循环当只存在一个包含所有对象的类时算法终止。(同哈夫曼树的思想很像)

##### 	2. 自顶向下

​		自顶向下算法也是一种贪心算法，其是按照组内最大化相似度的方法将它们聚集到不同的组中。开始时算法中只有一个包含所有样本数据的类别集合，因为相似度大的对象之间的内聚度也比较大，所以算法的每一个迭代步骤都是分割**最小内聚度**的类别集合。

​	同时，层级聚类还必须满足一个前提，即相似度函数是**单调函数**。因为其要满足在合并集合或者划分集合后，不会增加样本之间的相似性。

------

​	在具体的聚类中，重点是相似度的度量和计算。书中介绍了三种相似度函数，分别是：**单连通**、**全连通**和**平均连通**。

​	1.单连通

​		单连通方法的聚类有好的局部一致性，其不太会考虑全局的状况，并且会出现拉长聚类区域的特性(**链式效应**)。它是定义了两个集合间**最相似**样本之间的相似度，即两个类别中最近点的距离。时间复杂度是$O(n^2)$

​	2.全连通

​		全连通是定义了两个集合间**最不相似**样本之间的相似度，即两个类别中最远点的距离，时间复杂度是$O(n^3)$。全连通是更符合统计自然语言处理要求的相似度方法。

​	3.平均连通

​		平均连通是两个方法的折中方案，它将平均相似度作为聚类准则，且时间复杂度为$O(n^2)$。

​	相似度的具体计算方法，可以使用**余弦法**，即：

​	$sim(\vec{x},\vec{y})=cos(\vec{x},\vec{y})=\frac{\vec{x} \cdot \vec{y}}{\abs{\vec{x}}\abs{\vec{y}}}=\frac{\sum^m_{i=1}x_i\times y_i}{\sqrt{\sum^m_{i=1}x_i^2 \times \sqrt{\sum^m_{i=1}y_i^2}}}=\vec{x} \cdot \vec{y}$

------

​	在聚类改进语言模型上的应用是，我们可以通过聚类来建立一个更准确的语言模型。比如语音识别中，判断$President\ Kennedy$和$precedent\ Kennedy$，这两个短语发音完全一样，但是语言模型可以告诉我们第一个更有可能。它的推理是基于噪声信道模型的，有很好的效果，而模型中加入了聚类可以更好地进一步改进语言模型质量。

​	通过319页的语言模型的推导公式，我们可以知道最优的语言模型是应该选择**互信息最大**的聚类集合来进行实现的。那么我们定义一个互信息损失函数，即：

​	$MI-loss(c_i,c_j)=\sum\limits_{c_k \in C\\(c_i,c_j)}I(c_k:c_i)+I(c_k:c_j)-I(c_k:c_i \cup c_j)$

​	由推导公式的结论，我们选择信息损失最小的原则来选定两个集合进行合并操作，即：

​	$(c_{n_1},c_{n_2}):=arg\min\limits_{(c_i,c_j \in C \times C)} MI-loss(c_i,c_j)$

​	聚类过程的终止条件是聚类数目达到一个预定义的阈值$k$。

#### 3. 非层级聚类

​	非层级聚类有一个初始划分假设，任何样本都可以作为初始的聚类中心点，然后在此基础上不断地更新聚类划分，从而最终实现聚类。本书主要介绍了两种方法：$K-Means$和$EM$算法。

 1. $K-Means$方法

    算法的思想：开始时设定初始的聚类中心，将样本类别判定为据某类别中心最近的那个类别，然后再进行类别中心更新，不断迭代，直到收敛。可以查看我这篇实现好的$K-Means$方法并且在课程$Assignment$中获得了满分：[https://mrsuncodes.github.io/2021/09/06/%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A-%E5%AE%9E%E7%8E%B0k-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-%E6%BB%A1%E5%88%86%E4%BB%A3%E7%A0%81%E4%B8%8E%E6%80%9D%E8%B7%AF/](https://mrsuncodes.github.io/2021/09/06/%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A-%E5%AE%9E%E7%8E%B0k-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-%E6%BB%A1%E5%88%86%E4%BB%A3%E7%A0%81%E4%B8%8E%E6%80%9D%E8%B7%AF/)

    这里需要注意的是：k平均算法对脏数据很敏感，所以我们可以采用各种k平均的变种来解决问题。并且，因为初始聚类中心点是随机选取的，如果数据本身定义不太明确的情况下，最后的聚类结果可能不同。这些都可以从这里找到：https://github.com/MrSunCodes/Data-Mining-UIUC/tree/main/Cluster%20Analysis](https://github.com/MrSunCodes/Data-Mining-UIUC/tree/main/Cluster%20Analysis)。

 2. $EM$算法

    $EM$算法更像一个思想，而不是一个具体算法。简而言之就是我们只能看到一些观察到的数据，而看不到这些数据背后的隐含变量。我们需要根据观察到的数据来推导隐含变量是某个确切分布的概率，这就是$EM$算法想要去做的事情。
    
    要理解这个算法，可以结合下面两个视频去理解：
    
    [简单宏观地介绍EMalgorithm](https://www.bilibili.com/video/BV1Kr4y127Xy/)
    
    [EM Algorithm的具体例子](https://www.bilibili.com/video/BV183411177r/)
    
    对于$EM$算法来说，主要是$E-step$和$M-setp$。$E-step$通过已知的观察样本和先验概率以及随机初始化的值，去估计隐含变量的值，$M-setp$通过$E-step$中隐含变量的值反过来更新先验概率。通过不停地迭代，最终随机初始化的值将会收敛到一定范围。
    
    对$EM$算法的学习，不要参考课本上的内容，直接去阅读李航老师那本统计学习方法也可以。

------

​	这一章重点讲解了聚类在自然语言处理中的使用。比较重要的有聚类的方法以及$EM算法$，$EM$算法在前几章也有应用，包括$Baum-Welch算法$和向内-向外算法。
